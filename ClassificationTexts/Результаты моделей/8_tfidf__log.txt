Model Parameters:
Dense Layer:
Layer 1: 512 neurons, ReLU activation, Dropout 0.5
Layer 2: 256 neurons, ReLU activation, Dropout 0.5
Loss Function: categorical_crossentropy
Optimizer: Adam
Metrics: Accuracy
Epochs: 100
Batch Size: 32

Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.97      0.90        29
           1       1.00      0.50      0.67         2
           2       0.50      0.33      0.40         3
           3       1.00      1.00      1.00         3
           4       0.93      0.88      0.90        16
           5       1.00      0.75      0.86         4
           7       1.00      1.00      1.00         2

    accuracy                           0.88        59
   macro avg       0.90      0.77      0.82        59
weighted avg       0.88      0.88      0.87        59

Macro F1 Score: 0.818608733816107